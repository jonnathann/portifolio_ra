{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de imagens com Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Exploratória (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lista de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de classes\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrar 10 imagens aleatórias com labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "for i in range(10):\n",
    "    idx = np.random.randint(0, len(x_train))\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(x_train[idx])\n",
    "    plt.title(classes[int(y_train[idx])])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizar os dados (de 0-255 para 0-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converter os rótulos para one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificar dimensões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando o modelo CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função importante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(history):\n",
    "    # Plotar os gráficos 2x2\n",
    "    history_dict = history.history\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "    # Acurácia - Treinamento\n",
    "    axs[0, 0].plot(history_dict['accuracy'], label='Treinamento')\n",
    "    axs[0, 0].set_title('Acurácia - Treino')\n",
    "    axs[0, 0].set_xlabel('Época')\n",
    "    axs[0, 0].set_ylabel('Acurácia')\n",
    "    axs[0, 0].grid(True)\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    # Acurácia - Validação\n",
    "    axs[0, 1].plot(history_dict['val_accuracy'], label='Validação', color='orange')\n",
    "    axs[0, 1].set_title('Acurácia - Validação')\n",
    "    axs[0, 1].set_xlabel('Época')\n",
    "    axs[0, 1].set_ylabel('Acurácia')\n",
    "    axs[0, 1].grid(True)\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    # Loss - Treinamento\n",
    "    axs[1, 0].plot(history_dict['loss'], label='Treinamento', color='green')\n",
    "    axs[1, 0].set_title('Loss - Treino')\n",
    "    axs[1, 0].set_xlabel('Época')\n",
    "    axs[1, 0].set_ylabel('Loss')\n",
    "    axs[1, 0].grid(True)\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    # Loss - Validação\n",
    "    axs[1, 1].plot(history_dict['val_loss'], label='Validação', color='red')\n",
    "    axs[1, 1].set_title('Loss - Validação')\n",
    "    axs[1, 1].set_xlabel('Época')\n",
    "    axs[1, 1].set_ylabel('Loss')\n",
    "    axs[1, 1].grid(True)\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo arquitetura da CNN comum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_CIFAR10(x_train, y_train, x_test, y_test, epochs, sumarity=True):\n",
    "    # Definir a arquitetura do modelo\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1ª camada convolucional\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # 2ª camada convolucional\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # 3ª camada convolucional\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Achatar e adicionar densa\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))  # Regularização\n",
    "\n",
    "    # Saída - 10 classes (CIFAR-10)\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Compilar o modelo\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Callbacks\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    # Resumo da arquitetura\n",
    "    if sumarity:\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    # Treinamento do modelo\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=64,\n",
    "        validation_data=(x_test, y_test),\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    #Plotando gráficos\n",
    "    plots(history)\n",
    "\n",
    "    return model\n",
    "\n",
    "CNN_CIFAR10(0, 0, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo arquitetura da CNN com data argumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_CIFAR10(x_train, y_train, x_test, y_test, epochs, summary=True, use_augmentation=False):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1º bloco conv\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # 2º bloco conv\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # 3º bloco conv\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Flatten + Dense\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Compilação\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    if summary:\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    # Callbacks\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    if use_augmentation:\n",
    "        print(\"Usando Data Augmentation...\")\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            horizontal_flip=True\n",
    "        )\n",
    "        datagen.fit(x_train)\n",
    "\n",
    "        history = model.fit(\n",
    "            datagen.flow(x_train, y_train, batch_size=64),\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_test, y_test),\n",
    "            callbacks=[early_stop]\n",
    "        )\n",
    "    else:\n",
    "        history = model.fit(\n",
    "            x_train, y_train,\n",
    "            batch_size=64,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_test, y_test),\n",
    "            callbacks=[early_stop]\n",
    "        )\n",
    "\n",
    "    #Plotando gráficos\n",
    "    plots(history)\n",
    "\n",
    "    return model\n",
    "\n",
    "CNN_CIFAR10(0, 0, 0, 0, 0, summary=True, use_augmentation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando o modelo CNN comum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_CIFAR10(x_train, y_train_cat, x_test, y_test_cat, 20, sumarity=False)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test_cat, verbose=2)\n",
    "print('Erro:', test_loss, 'Acurácia:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando CNN com data argumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  CNN_CIFAR10(x_train, y_train_cat, x_test, y_test_cat, 20, summary=False, use_augmentation=True)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test_cat, verbose=2)\n",
    "print('Erro:', test_loss, 'Acurácia:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
